```[1]Sonnekalb T, Heinze T S, Mäder P. Deep security analysis of program code: A systematic literature review[J]. Empirical Software Engineering, 2022, 27(1): 2.```

## 一、概述
#### 1.文在六个问题进行了叙述————深度学习在源代码漏洞检测的发展史、数据集是怎么格式化和打标签的、代码应该如何表征以适应学习模型、当前应用的模型有哪些、模型应该如何评估、模型的可泛化性。
## 二、数据集
#### 1.数据集的大小和格式：
```
数据集的大小会直接影响学习质量，按理说，数据集越大，学习效果越好
```
#### 2.综合训练数据：
```
通过良好的权衡真实世界的代码和代码生成器生成的代码，能够提高学习效率
```
#### 3.标签生成：
```
现在的深度学习应用基本都是监督学习，标签一般是人手动定义的，也可以通过标签生成器进行生成
```
#### 4.标签粒度：
```
标签粒度基本能够决定学习模型的任务完成粒度
```
#### 5.标签平衡：
```
就漏洞检测来说，标签就是漏洞代码和非漏洞代码的二元分类，那么在训练数据集中，漏洞代码和非漏洞代码应该在一个平衡的比值，40%比较合适
```
#### 6.漏洞类型：
```
通常来说，现有模型都是对未知代码检测出已知类型的漏洞，而非未知类型的漏洞，所以漏洞类型通常是确定的，比如NVD、SARD都由确定的漏洞类型
```
#### 7.基准数据集：
```
基本是NVD和SARD
```
## 三、代码表征和编码
#### 1.训练样本粒度：
```
代码表征粒度就决定了模型的粒度，现有粒度都集中在函数，而非语句。预测结果还需要开发人员在函数内排查，在语句级别的模型研发较少
```
#### 2.代码语言和格式：
```
通常都是对C/C++进行训练和检测，因为他们能够接触底层，所以被视为最不安全的原因呢。但是像python/java这种语言虽然能够避免字节层面的漏洞，但是还是会有缓冲区溢出等高层次的漏洞
```
#### 3.中间代码表示：
```
根据训练模型，由序列和图两种
```
#### 4.序列化：
```
可以通过token分析，或者在AST中DPS遍历得出每个叶子节点的路径
```
#### 5.词嵌入：
```
例如word2vec，直接将词转为向量
```
#### 6.图嵌入：
```
例如GGRU、GCN等模型，以及structure2vec、doc2vec框架
```
## 四、模型研究
#### 1.通常是RNN初步实验，LSTM、GRU更高级，BLSTM更高级
#### 2.深度递归拓扑：如BiLSTM
#### 3.前馈拓扑：例如CNN
#### 4.图拓扑：GNN和GCN
## 五、模型评估
#### 1.评估指标：没有统一标准，通常结合下游任务
#### 2.交叉验证
#### 3.比较评估
## 六、模型泛化
#### 1.跨项目学习
#### 2.转移学习：
```
两个学习阶段：预训练，使用更大的数据集进行预训练；微调优化，使用实际数据集对模型进行微调优化
```
## 七、发展方法
#### 1.跨语言、跨项目
#### 2.其他拓扑网络结构
#### 3.无监督学习
#### 4.粒度细化